# Generated by Django 6.0.2 on 2026-02-11 19:39

from django.db import migrations, models
from django.db.models.functions import Lower


def deduplicate_addresses(apps, schema_editor):
    """Merge Address rows that differ only by case.

    For each group of case-insensitive duplicates we keep the oldest row
    (lowest pk), re-point every Location FK to it, and delete the rest.
    The stored data is NOT lowercased — original casing is preserved.
    """
    Address = apps.get_model("common", "Address")
    Location = apps.get_model("common", "Location")

    from django.db.models import Count, Min, Value
    from django.db.models.functions import Coalesce

    # Group by lowered values; Coalesce maps NULL → "" so NULLs group together.
    dupes = (
        Address.objects.values(
            norm_street=Coalesce(Lower("street"), Value("")),
            norm_city=Coalesce(Lower("city"), Value("")),
            norm_state=Coalesce(Lower("state"), Value("")),
            norm_zip=Coalesce(Lower("zip_code"), Value("")),
        )
        .annotate(cnt=Count("id"), keep_id=Min("id"))
        .filter(cnt__gt=1)
    )

    for group in dupes:
        keep_id = group["keep_id"]
        duplicates = (
            Address.objects.annotate(
                norm_street=Coalesce(Lower("street"), Value("")),
                norm_city=Coalesce(Lower("city"), Value("")),
                norm_state=Coalesce(Lower("state"), Value("")),
                norm_zip=Coalesce(Lower("zip_code"), Value("")),
            )
            .filter(
                norm_street=group["norm_street"],
                norm_city=group["norm_city"],
                norm_state=group["norm_state"],
                norm_zip=group["norm_zip"],
            )
            .exclude(id=keep_id)
        )
        dup_ids = list(duplicates.values_list("id", flat=True))

        # Re-point Locations that reference a duplicate.
        Location.objects.filter(address_id__in=dup_ids).update(address_id=keep_id)

        # Delete the duplicate Address rows.
        Address.objects.filter(id__in=dup_ids).delete()


class Migration(migrations.Migration):

    dependencies = [
        ("common", "0018_fix_file_extensions"),
    ]

    operations = [
        migrations.RunPython(
            deduplicate_addresses,
            reverse_code=migrations.RunPython.noop,
        ),
        migrations.RemoveIndex(
            model_name="address",
            name="address_index",
        ),
        migrations.AddIndex(
            model_name="address",
            index=models.Index(
                Lower("street"),
                Lower("city"),
                Lower("state"),
                Lower("zip_code"),
                name="address_lookup_idx",
            ),
        ),
    ]
